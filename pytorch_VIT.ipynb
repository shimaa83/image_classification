{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DqqsWiX2-Rcp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob as gb\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from torchsummary import summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-EKpcj7Y-3Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a39848-fb99-472d-bcc8-0ffb17ef001b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "in_channels = 3\n",
        "num_classes = 4\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "# Load Data\n",
        "trainpath ='/content/drive/MyDrive/covid19/pytorch3/train/'\n",
        "testpath='/content/drive/MyDrive/covid19/pytorch3/test/'\n",
        "valpath='/content/drive/MyDrive/covid19/pytorch3/val/'\n",
        "\n",
        "img_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=(224,224)), \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), \n",
        "        ]),\n",
        "\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=(224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), \n",
        "        ]),\n",
        "        'val':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=(224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), \n",
        "        ]),\n",
        "     }\n",
        "\n",
        "train_dataset=datasets.ImageFolder(trainpath,transform=img_transforms['train'])\n",
        "test_dataset=datasets.ImageFolder(testpath,transform=img_transforms['test'])\n",
        "val_dataset=datasets.ImageFolder(testpath,transform=img_transforms['val'])\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "it=iter(train_loader)\n",
        "images,label=it.next()\n",
        "print(images.shape)\n",
        "print(label.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUaJlyp43_EF",
        "outputId": "06ee84fe-a922-4f46-c39e-e888dad68960"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 224, 224])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs,model,train_loader):\n",
        "\n",
        "# Loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "  trainingloss = []\n",
        "  validationloss = []\n",
        "# Train the model\n",
        "  total_step = len(train_loader)\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "              \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    model.eval()  \n",
        "    with torch.no_grad():\n",
        "       correct = 0\n",
        "       total = 0\n",
        "       for images, labels in val_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    acc=(100 * correct / total)    \n",
        "          # printing training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch,acc))"
      ],
      "metadata": {
        "id": "dJRkHup6IzcS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "def test(model,test_loader): \n",
        "\n",
        "  model.eval()  \n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model is: {} %'.format(100 * correct / total))\n"
      ],
      "metadata": {
        "id": "PwIlss3Uabrb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytorch-pretrained-vit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FymnHhLf_Kvn",
        "outputId": "0f03412f-facb-4120-f484-2ca5a31deba6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-vit\n",
            "  Downloading pytorch-pretrained-vit-0.0.7.tar.gz (13 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-vit) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-pretrained-vit) (4.1.1)\n",
            "Building wheels for collected packages: pytorch-pretrained-vit\n",
            "  Building wheel for pytorch-pretrained-vit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-pretrained-vit: filename=pytorch_pretrained_vit-0.0.7-py3-none-any.whl size=11132 sha256=008cdf4003c5f5a861072c57f5f5e359dfc2f0047c5df9120d69d2f5c27d17ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/1d/d1/c6852ef6d18565e5aee866432ab40c6ffbd3411d592035cddb\n",
            "Successfully built pytorch-pretrained-vit\n",
            "Installing collected packages: pytorch-pretrained-vit\n",
            "Successfully installed pytorch-pretrained-vit-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_vit import ViT"
      ],
      "metadata": {
        "id": "ZIrZnzCs_OLr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "\n",
        "import timm\n",
        "\n",
        "class ViTBase16(nn.Module):\n",
        "    def __init__(self, n_classes, pretrained=False):\n",
        "\n",
        "        super(ViTBase16, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
        "\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO0vSNnrA-_t",
        "outputId": "f59c409a-f5e3-4e17-af53-a9fc57182e4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.6.7)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTBase16(n_classes=4, pretrained=True)\n"
      ],
      "metadata": {
        "id": "DLcZ9w_XCDml"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=50\n",
        "\n",
        "train(num_epochs,model,train_loader)\n",
        "#session crached every time i run this code"
      ],
      "metadata": {
        "id": "9h7SGdX6C0q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model,test_loader)"
      ],
      "metadata": {
        "id": "TX1LjTTqDEUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}