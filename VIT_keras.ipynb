{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DqqsWiX2-Rcp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob as gb\n",
        "import cv2\n",
        "import shutil\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, AvgPool2D, Input, Dropout, Flatten, BatchNormalization\n",
        "from keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-EKpcj7Y-3Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e603ca8-63ef-4ce6-92b6-d35cc2c021bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8AVcwV_g-pqw"
      },
      "outputs": [],
      "source": [
        "trainpath ='/content/drive/MyDrive/covid19/dataset-covid/train/'\n",
        "testpath='/content/drive/MyDrive/covid19/dataset-covid/test/'\n",
        "Valpath='/content/drive/MyDrive/covid19/dataset-covid/val/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing data set\n",
        "#convert image to RGB\n",
        "#resize Image\n",
        "#label image"
      ],
      "metadata": {
        "id": "diN7x0IulG62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x_train,y_train\n",
        "#due to session crash i will take only 500 image\n",
        "new_size=224    \n",
        "X_train = []\n",
        "y_train = []\n",
        "for folder in  os.listdir(trainpath) : \n",
        "    print( 'folder name is : ', folder)\n",
        "    files = gb.glob(pathname= str( trainpath  + folder + '/*.png'))\n",
        "    print( 'numbers of images in folder are : ', len(files))\n",
        "    count=0\n",
        "    for file in files: \n",
        "        image_class = {'covid': 0, 'Lung-Opacity': 1,'Normal':2,'viral-Pneumonia':3}\n",
        "        orignal_image = cv2.imread(file)\n",
        "        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)\n",
        "        resized_image = cv2.resize(image , (new_size,new_size))\n",
        "        X_train.append(resized_image)\n",
        "        y_train.append(image_class[folder])\n",
        "        count=count+1\n",
        "        if(count==300):\n",
        "          break\n",
        "\n",
        "print(\"X_train:       \",len(X_train) ) \n",
        "print(\"y_train:       \",len(y_train) ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv0Ki71Bc10T",
        "outputId": "7070159e-39f4-4806-ddb7-0c578b33a17b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder name is :  covid\n",
            "numbers of images in folder are :  2531\n",
            "folder name is :  Lung-Opacity\n",
            "numbers of images in folder are :  4208\n",
            "folder name is :  Normal\n",
            "numbers of images in folder are :  1508\n",
            "folder name is :  viral-Pneumonia\n",
            "numbers of images in folder are :  941\n",
            "X_train:        1200\n",
            "y_train:        1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juK_x7vXI791",
        "outputId": "ab9d0249-61fa-47e7-b477-e9d7d8aa1e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder name is :  covid\n",
            "numbers of images in folder are :  724\n",
            "folder name is :  Lung-Opacity\n",
            "numbers of images in folder are :  1203\n",
            "folder name is :  Normal\n",
            "numbers of images in folder are :  2039\n",
            "folder name is :  viral-Pneumonia\n",
            "numbers of images in folder are :  270\n",
            "X_test:        400\n",
            "y_test:        400\n"
          ]
        }
      ],
      "source": [
        "#300\n",
        "#x_test,y_test\n",
        "new_size=224    \n",
        "X_test = []\n",
        "y_test = []\n",
        "for folder in  os.listdir(testpath) : \n",
        "    print( 'folder name is : ', folder)\n",
        "    files = gb.glob(pathname= str( testpath  + folder + '/*.png'))\n",
        "    print( 'numbers of images in folder are : ', len(files))\n",
        "    count=0\n",
        "    for file in files: \n",
        "        image_class = {'covid': 0, 'Lung-Opacity': 1,'Normal':2,'viral-Pneumonia':3}\n",
        "        orignal_image = cv2.imread(file)\n",
        "        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)\n",
        "        resized_image = cv2.resize(image , (new_size,new_size))\n",
        "        X_test.append(resized_image)\n",
        "        y_test.append(image_class[folder])\n",
        "        count=count+1\n",
        "        if(count==100):\n",
        "          break\n",
        "\n",
        "print(\"X_test:       \",len(X_test) ) \n",
        "print(\"y_test:       \",len(y_test) ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGhvKFsVIxtA",
        "outputId": "77dd2d00-f47c-40ac-d60e-34ab772fc7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder name is :  covid\n",
            "numbers of images in folder are :  361\n",
            "folder name is :  Lung-Opacity\n",
            "numbers of images in folder are :  601\n",
            "folder name is :  Normal\n",
            "numbers of images in folder are :  1019\n",
            "folder name is :  viral-Pneumonia\n",
            "numbers of images in folder are :  134\n",
            "X_val is:        734\n",
            "y_val is:        734\n"
          ]
        }
      ],
      "source": [
        "#x_validation ,y_validation\n",
        "#200\n",
        "new_size=224    \n",
        "X_val = []\n",
        "y_val = []\n",
        "for folder in  os.listdir(Valpath ) : \n",
        "    print( 'folder name is : ', folder)\n",
        "    files = gb.glob(pathname= str( Valpath  + folder + '/*.png'))\n",
        "    print( 'numbers of images in folder are : ', len(files))\n",
        "    count=0\n",
        "    for file in files: \n",
        "        image_class = {'covid': 0, 'Lung-Opacity': 1,'Normal':2,'viral-Pneumonia':3}\n",
        "        orignal_image = cv2.imread(file)\n",
        "        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)\n",
        "        resized_image = cv2.resize(image , (new_size,new_size))\n",
        "        X_val.append(list(resized_image))\n",
        "        y_val.append(image_class[folder])\n",
        "        count=count+1\n",
        "        if(count==200):\n",
        "          break\n",
        "print(\"X_val is:       \",len(X_val) ) \n",
        "print(\"y_val is:       \",len(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pHk6AqYNLO9Y"
      },
      "outputs": [],
      "source": [
        "#convert to numpy array\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "N25vW0LvLRfa"
      },
      "outputs": [],
      "source": [
        "#using categorical method\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train,4)\n",
        "y_val = to_categorical(y_val,4)\n",
        "y_test = to_categorical(y_test,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qgG8KkTlLbAd"
      },
      "outputs": [],
      "source": [
        "#shuffel data\n",
        "from sklearn.utils import shuffle\n",
        "X_train,y_train = shuffle(X_train,y_train)\n",
        "X_val,y_val = shuffle(X_val,y_val)\n",
        "X_test,y_test = shuffle(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zcoJARtoLeCh"
      },
      "outputs": [],
      "source": [
        "#last step using normalization\n",
        "X_train=X_train/255.0\n",
        "X_val=X_val/255.0\n",
        "X_test=X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VIT transformer"
      ],
      "metadata": {
        "id": "BdEIrQ0DiHfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-addons\n",
        "\n",
        "!pip install vit-keras\n",
        "from vit_keras import vit\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN1dZwsBA-0o",
        "outputId": "5c9ff6c7-4d39-4b20-ae0c-592941c31575"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 29.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vit-keras in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vit-keras) (1.7.3)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from vit-keras) (0.20.0)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->vit-keras) (1.21.6)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->vit-keras) (4.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "model = vit.vit_l32(\n",
        "    image_size=image_size,\n",
        "    activation='softmax',\n",
        "    pretrained=True,\n",
        "    include_top=True,\n",
        "    pretrained_top=False,\n",
        "    classes=4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYj5n85EMsXt",
        "outputId": "41e83e84-7d2b-4460-cf4c-f145a141e40b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-L_32_imagenet21k+imagenet2012.npz\n",
            "1226661888/1226658854 [==============================] - 261s 0us/step\n",
            "1226670080/1226658854 [==============================] - 261s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 12, 12 to 7, 7\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrqj6l17EeES",
        "outputId": "7827cf28-d12c-4f74-89c7-36bf0d441c19"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vit-l32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " embedding (Conv2D)          (None, 7, 7, 1024)        3146752   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 49, 1024)          0         \n",
            "                                                                 \n",
            " class_token (ClassToken)    (None, 50, 1024)          1024      \n",
            "                                                                 \n",
            " Transformer/posembed_input   (None, 50, 1024)         51200     \n",
            " (AddPositionEmbs)                                               \n",
            "                                                                 \n",
            " Transformer/encoderblock_0   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_1   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_2   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_3   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_4   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_5   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_6   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_7   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_8   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_9   ((None, 50, 1024),       12596224  \n",
            " (TransformerBlock)           (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_10  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_11  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_12  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_13  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_14  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_15  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_16  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_17  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_18  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_19  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_20  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_21  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_22  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_23  ((None, 50, 1024),       12596224  \n",
            "  (TransformerBlock)          (None, 16, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoder_norm (L  (None, 50, 1024)         2048      \n",
            " ayerNormalization)                                              \n",
            "                                                                 \n",
            " ExtractToken (Lambda)       (None, 1024)              0         \n",
            "                                                                 \n",
            " head (Dense)                (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 305,514,500\n",
            "Trainable params: 305,514,500\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train last layer\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "epochs = 10\n",
        "earlystop = EarlyStopping(\"val_accuracy\", patience=5, verbose=1, restore_best_weights=True,)\n",
        "history = model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=epochs,callbacks=[earlystop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Waa6lOmk_P",
        "outputId": "4cea70c7-c868-447f-8110-a0fca467d2fb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "38/38 [==============================] - 97s 2s/step - loss: 1.8145 - accuracy: 0.2733 - val_loss: 1.4426 - val_accuracy: 0.1826\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 49s 1s/step - loss: 1.4209 - accuracy: 0.2483 - val_loss: 1.3884 - val_accuracy: 0.2725\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 48s 1s/step - loss: 1.4284 - accuracy: 0.2325 - val_loss: 1.4025 - val_accuracy: 0.2725\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 48s 1s/step - loss: 1.4058 - accuracy: 0.2450 - val_loss: 1.4180 - val_accuracy: 0.1826\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 48s 1s/step - loss: 1.4033 - accuracy: 0.2475 - val_loss: 1.3749 - val_accuracy: 0.2725\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 48s 1s/step - loss: 1.4036 - accuracy: 0.2408 - val_loss: 1.3749 - val_accuracy: 0.2725\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4090 - accuracy: 0.2575Restoring model weights from the end of the best epoch: 2.\n",
            "38/38 [==============================] - 49s 1s/step - loss: 1.4090 - accuracy: 0.2575 - val_loss: 1.3789 - val_accuracy: 0.2725\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZUuenE2nAlG",
        "outputId": "2dd62f72-7cd2-4abf-d686-b00f27bbd9bc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 4s 335ms/step - loss: 1.4094 - accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.409368634223938, 0.25]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}